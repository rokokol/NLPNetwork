{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-07T08:24:24.525485Z",
     "start_time": "2024-04-07T08:24:21.506176Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "with open('Source/reviews.txt') as r, open('Source/labels.txt') as l:\n",
    "    raw_reviews = r.readlines()\n",
    "    raw_labels = l.readlines()\n",
    "    \n",
    " \n",
    "tokens = list(map(lambda x: set(x.split(\" \")), raw_reviews))\n",
    "\n",
    "vocab_raw = list(set([word for token in tokens for word in token if len(word) > 0 and word[0].isalpha()]))\n",
    "vocab = list(set([''.join([w for w in word if w.isalpha()]) for word in vocab_raw]))\n",
    "\n",
    "word2index = {w:i for i, w in enumerate(vocab)}\n",
    "input_dataset = [list(set([word2index[word] for word in token if word in word2index])) for token in tokens]\n",
    "    \n",
    "target_dataset = [int(label == 'positive\\n') for label in raw_labels]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1 progress: 95.99 accurancy: 0.86637583100645977"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "sigder = lambda x: x * (1 - x)\n",
    "alpha, iterations = 0.01, 2\n",
    "hidden_size = 100\n",
    "\n",
    "weights_0_1 = 0.2 * np.random.random((len(vocab), hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2 * np.random.random((hidden_size, 1)) - 0.1\n",
    "\n",
    "correct, total = 0, 0\n",
    "for iter in range(iterations):\n",
    "    for i in range(len(input_dataset) - 1000):\n",
    "        x, y = input_dataset[i], target_dataset[i]\n",
    "        layer_1 = sigmoid(np.sum(weights_0_1[x], axis=0))\n",
    "        layer_2 = sigmoid(layer_1 @ weights_1_2)\n",
    "\n",
    "        layer_2_delta = (np.abs(layer_2)- y)\n",
    "        layer_1_delta = (layer_2_delta @ weights_1_2.T)\n",
    "\n",
    "        weights_0_1[x] -= layer_1_delta * alpha\n",
    "        weights_1_2 -= np.outer(layer_1, layer_2_delta) * alpha\n",
    "\n",
    "        if np.abs(layer_2 - y) < 0.5:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "        if i % 10 == 9:\n",
    "            progres = str(i / (len(input_dataset)) * 100)\n",
    "            sys.stdout.write('\\rIter: ' + str(iter) + \\\n",
    "                             ' progress: ' + str(progres)[:5] + \\\n",
    "                             ' accurancy: ' + str(correct / total))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T08:24:32.300143Z",
     "start_time": "2024-04-07T08:24:24.526813Z"
    }
   },
   "id": "83daffd6f7eea0d3",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "\n",
    "def test(inp):\n",
    "    inp = ''.join([i for i in inp if i.isalpha() or i == ' '])\n",
    "    x = list(set([word2index[word] for word in inp.split() if word in vocab]))\n",
    "    layer_1 = sigmoid(np.sum(weights_0_1[x], axis=0))\n",
    "    layer_2 = sigmoid(layer_1 @ weights_1_2)\n",
    "    return layer_2\n",
    "\n",
    "\n",
    "def similar(target='beautiful'):\n",
    "    target_index = word2index[target]\n",
    "    scores = Counter()\n",
    "    for word,index in word2index.items():\n",
    "        raw_difference = weights_0_1[index] - (weights_0_1[target_index])\n",
    "        squared_difference = raw_difference * raw_difference\n",
    "        scores[word] = -math.sqrt(sum(squared_difference))\n",
    "\n",
    "    return scores.most_common(10)\n",
    "\n",
    "def analogy(positive=['terrible', 'good'], negative=['bad']):\n",
    "    norms = np.sum(weights_0_1 * weights_0_1, axis=1)\n",
    "    norms.resize(norms.shape[0], 1)\n",
    "\n",
    "    normed_weights = weights_0_1 * norms\n",
    "    # normed_weights = weights_0_1**2\n",
    "\n",
    "    query_vect = np.zeros(len(weights_0_1[0]))\n",
    "    for word in positive:\n",
    "        query_vect += normed_weights[word2index[word]]\n",
    "    for word in negative:\n",
    "        query_vect -= normed_weights[word2index[word]]\n",
    "\n",
    "    scores = Counter()\n",
    "    for word, index in word2index.items():\n",
    "        raw_difference = weights_0_1[index] - query_vect\n",
    "        scores[word] = -math.sqrt(sum(raw_difference * raw_difference))\n",
    "    return scores.most_common(10)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T08:27:48.583095Z",
     "start_time": "2024-04-07T08:27:48.575185Z"
    }
   },
   "id": "205afe62088e5dc3",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[('worst', -4.4524872396962945),\n ('waste', -4.847852489286),\n ('awful', -4.960861199856841),\n ('poorly', -5.291051918021452),\n ('disappointment', -5.616241126567832),\n ('disappointing', -5.617300091056642),\n ('dull', -5.696591326973348),\n ('boring', -5.706431864718387),\n ('annoying', -5.710001674331351),\n ('terrible', -5.754966477012552)]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy(['bad'], ['amazing'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T08:28:48.499870Z",
     "start_time": "2024-04-07T08:28:47.593482Z"
    }
   },
   "id": "6961b427a7686ceb",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.55161954])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test('fallacies')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T08:28:04.365783Z",
     "start_time": "2024-04-07T08:28:04.361830Z"
    }
   },
   "id": "a32b42608bef4730",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "from sympy.abc import x\n",
    "\n",
    "\n",
    "f = 1 / (1 - x**3)\n",
    "f.diff()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48cc249fc8397f55",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8b2c095ee44ea06"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
